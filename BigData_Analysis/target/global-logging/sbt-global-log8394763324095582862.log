[0m[[0m[0mdebug[0m] [0m[0m> Exec(collectAnalyses, None, Some(CommandSource(network-1)))[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":4,"message":"Processing"})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: initialized: JsonRpcNotificationMessage(2.0, initialized, {})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///Users/rohith/git/19AIE214-BDA/BigData_Analysis/Jan/JanRdd_2.scala","languageId":"scala","version":1,"text":"\nval files = scala.io.Source.fromFile(\"files.txt\").getLines.toArray.map{n=>n.split('.')(0)}\nfor (i <- 0 until files.length){\n    val ds = files(i)\n    val iRdd = sc.textFile(ds+\".trd\").map(l =>  ds+'|'+l)\n    iRdd.saveAsTextFile(ds)\n}\nval nseJanRdd = sc.textFile(\"*/part*\")\nnseJanRdd.take(10).foreach(println)\n\nval nseFreqRdd = nseJanRdd.map{l=>\n    val s = l.split('|')\n    ((s(0).toInt,s(4)),1)}.reduceByKey(_+_)\n\nnseFreqRdd.sortBy(_._1).toDF.show(false)\nval nseDayFreqArray = nseFreqRdd.map{case ((d,t),f)=>(d,f)}.reduceByKey(_+_).sortBy(_._1).collect"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///Users/rohith/git/19AIE214-BDA/BigData_Analysis/build.sbt","languageId":"scala","version":1,"text":"name := \"BigData_Analysis\"\nversion := \"1.0\"\nscalaVersion := \"2.12.10\"\n\n// https://mvnrepository.com/artifact/org.apache.spark/spark-core\nlibraryDependencies += \"org.apache.spark\" %% \"spark-core\" % \"3.1.1\"\n\n// https://mvnrepository.com/artifact/org.apache.spark/spark-sql\nlibraryDependencies += \"org.apache.spark\" %% \"spark-sql\" % \"3.1.1\""}})[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / collectAnalyses[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: bloop.integrations.sbt.Offloader$$anon$1@35fb3209, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0manalysis location (/Users/rohith/git/19AIE214-BDA/BigData_Analysis/target/scala-2.12/zinc/inc_compile_2.12.zip,true)[0m
[0m[[0m[32msuccess[0m] [0m[0mTotal time: 1 s, completed 30 Mar, 2021 10:38:55 PM[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":4,"message":"Done"})[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0mForcing garbage collection...[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///Users/rohith/git/19AIE214-BDA/BigData_Analysis/JanRdd.scala","languageId":"scala","version":1,"text":"object JanRDD{\nval nseJan01Rdd = sc.textFile(\"/Users/rohith/git/19AIE214-BDA/BigData_Analysis/Jan/20150101.trd\")\n//val nseJanRdd = sc.textFile(\"/Users/rohith/git/19AIE214-BDA/BigData_Analysis/Jan/*.trd\")\nnseJan01Rdd.count\nnseJan01Rdd.toDF.show(false)\nval freqJan01Rdd = nseJan01Rdd.map{l=>\n    val str = l.split('|')\n    (str(3),1) }\nfreqJan01Rdd.reduceByKey(_+_).sortBy(_._1).toDF.show(100)\n}"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: $/setTraceNotification: JsonRpcNotificationMessage(2.0, $/setTraceNotification, {"value":"off"})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didClose: JsonRpcNotificationMessage(2.0, textDocument/didClose, {"textDocument":{"uri":"file:///Users/rohith/git/19AIE214-BDA/BigData_Analysis/build.sbt"}})[0m
